---
title: Uk Building Regulations Bot
emoji: ğŸ“š
colorFrom: purple
colorTo: green
sdk: streamlit
sdk_version: 1.42.2
app_file: app.py
pinned: false
license: mit
---

Check out the configuration reference at https://huggingface.co/docs/hub/spaces-config-reference


## ğŸš§ StructureGPT: AI Assistant for UK Building Regulations
A Multi-Model Retrieval-Augmented Generation (RAG) System Fine-Tuned for Domain-Specific Compliance Guidance

## ğŸ” Overview
StructureGPT is a powerful, modular AI assistant designed to simplify access to UK Building Regulations. It compares three LLaMA-based language model configurations â€” including a LoRA fine-tuned model â€” in a shared RAG pipeline, enabling accurate, grounded, and efficient responses to complex regulatory queries.

## ğŸš€ Features
### âœ… Multi-Model RAG System: Supports LLaMA-3.3-70B, LLaMA3-8B via GROQ API, and a fine-tuned LLaMA-3.1-8B.
# âœ… Unified Streamlit Interface: Seamlessly switch between models and explore real-time comparisons.
âœ… Hybrid Retrieval: 70% vector search (ChromaDB + all-mpnet-base-v2) + 30% BM25 keyword matching.
âœ… Fine-Tuning with LoRA + Quantization: Efficient domain adaptation with 3,000+ curated Q&A pairs.
âœ… Fully Transparent Output: Source attribution, response times, and performance metrics included.

## ğŸ“· Interface Snapshot
![image](https://github.com/user-attachments/assets/bdae8ebc-1939-4c36-bacf-8e41ada9a7e2)
![image](https://github.com/user-attachments/assets/493a24e8-f178-4cf3-a28d-d2d3e4ef547b)



ğŸ§ª Try It Live:
ğŸ‘‰ StructureGPT on Hugging Face Spaces

## âš™ï¸ How It Works
graph TD;
    A[ğŸ“„ Official GOV.UK PDFs] --> B[ğŸ§  Content Extraction<br>(Unstructured API with YOLOX)]
    B --> C[ğŸ§© Paragraph-Based Chunking<br>+ Embedding (MPNet)]
    C --> D[ğŸ” Hybrid Retrieval Engine<br>(70% Vector Similarity + 30% BM25)]
    D --> E[ğŸ’¬ Unified Chat Interface<br>(Streamlit + LangChain)]
    E --> F[ğŸ§  Model Selector:<br>LLaMA-3.3-70B (GROQ)<br>LLaMA3-8B (GROQ)<br>Fine-Tuned LLaMA3.1-8B]


## ğŸ“¦ Stack & Tools
ğŸ’¬ LLMs: Metaâ€™s LLaMA-3 series (via GROQ API & Hugging Face)

ğŸ” RAG Stack: LangChain, ChromaDB, BM25, Sentence Transformers

ğŸ§  Fine-Tuning: LoRA (Rank=16, Alpha=32), 8-bit Quantization

ğŸ–¥ï¸ Deployment: Hugging Face Spaces + Streamlit

ğŸ§ª Evaluation: RAGAS, Giskard Toolkit

ğŸ“Š Tracking: Weights & Biases (wandb)    

