{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba24510-9ca5-4c00-bf50-fa280d4f4974",
   "metadata": {},
   "source": [
    "# Module 771764 – MSc Research Project\n",
    "\n",
    "## StructureGPT: Multi-Model Retrieval-Augmented Generation System for UK Building Regulations using Low-Rank Adaptation and Quantization\n",
    "### Student ID: 202403820 | Samuel Datubo Jaja\n",
    "### MSc Artificial Intelligence & Data Science | DAIM - Data-Science Artificial Intelligence & Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35c13e1-1250-4633-b6b3-36cb9d47d42e",
   "metadata": {},
   "source": [
    "# Notebook 1 - GOV.UK Data Collection and Preprocessing | RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c27dbf-37b5-4601-a236-4408088a79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9dc6b-ae0c-4392-aea6-b1dbac31063a",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d061f98-5467-459a-851c-39f3df393364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\program files\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\program files\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\program files\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python312\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\program files\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/212.5 MB 991.0 kB/s eta 0:03:35\n",
      "   ---------------------------------------- 0.1/212.5 MB 2.1 MB/s eta 0:01:41\n",
      "   ---------------------------------------- 0.3/212.5 MB 3.3 MB/s eta 0:01:05\n",
      "   ---------------------------------------- 0.5/212.5 MB 3.9 MB/s eta 0:00:54\n",
      "   ---------------------------------------- 1.1/212.5 MB 6.1 MB/s eta 0:00:35\n",
      "   ---------------------------------------- 2.2/212.5 MB 10.6 MB/s eta 0:00:20\n",
      "    --------------------------------------- 3.7/212.5 MB 14.8 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 6.4/212.5 MB 22.8 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 9.6/212.5 MB 30.7 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 12.6/212.5 MB 81.8 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 12.8/212.5 MB 65.6 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 13.0/212.5 MB 50.4 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 13.2/212.5 MB 50.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 13.6/212.5 MB 38.5 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 15.0/212.5 MB 36.4 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 17.2/212.5 MB 36.4 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 20.6/212.5 MB 36.4 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 24.3/212.5 MB 73.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 27.0/212.5 MB 93.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 29.2/212.5 MB 73.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 31.3/212.5 MB 72.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 32.9/212.5 MB 59.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 37.5/212.5 MB 72.6 MB/s eta 0:00:03\n",
      "   ------- ------------------------------- 42.6/212.5 MB 131.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------ 45.1/212.5 MB 108.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------ 48.8/212.5 MB 108.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 51.0/212.5 MB 93.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 53.2/212.5 MB 73.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 56.7/212.5 MB 81.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 58.0/212.5 MB 59.8 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 60.9/212.5 MB 65.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 63.9/212.5 MB 72.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 68.2/212.5 MB 93.0 MB/s eta 0:00:02\n",
      "   ------------- ------------------------- 74.2/212.5 MB 131.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------ 80.0/212.5 MB 165.0 MB/s eta 0:00:01\n",
      "   --------------- ----------------------- 84.6/212.5 MB 131.2 MB/s eta 0:00:01\n",
      "   ---------------- ---------------------- 90.4/212.5 MB 165.0 MB/s eta 0:00:01\n",
      "   ----------------- --------------------- 96.0/212.5 MB 162.4 MB/s eta 0:00:01\n",
      "   ------------------ ------------------- 101.8/212.5 MB 129.5 MB/s eta 0:00:01\n",
      "   ------------------ ------------------- 105.1/212.5 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------- ------------------- 106.3/212.5 MB 81.8 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 106.4/212.5 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 109.0/212.5 MB 54.4 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 115.2/212.5 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------------- ---------------- 120.5/212.5 MB 162.4 MB/s eta 0:00:01\n",
      "   ---------------------- --------------- 125.0/212.5 MB 165.0 MB/s eta 0:00:01\n",
      "   ----------------------- -------------- 129.8/212.5 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------ ------------- 135.2/212.5 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------- ------------ 140.3/212.5 MB 162.4 MB/s eta 0:00:01\n",
      "   -------------------------- ----------- 146.5/212.5 MB 131.2 MB/s eta 0:00:01\n",
      "   --------------------------- ---------- 153.6/212.5 MB 162.4 MB/s eta 0:00:01\n",
      "   ---------------------------- --------- 158.9/212.5 MB 162.4 MB/s eta 0:00:01\n",
      "   ----------------------------- -------- 164.5/212.5 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------ ------- 169.2/212.5 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------- ------ 175.2/212.5 MB 165.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ----- 181.2/212.5 MB 165.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ---- 186.8/212.5 MB 165.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- --- 192.5/212.5 MB 162.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- -- 197.7/212.5 MB 129.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- -- 200.5/212.5 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ - 205.8/212.5 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------------------------------  210.4/212.5 MB 165.0 MB/s eta 0:00:01\n",
      "   -------------------------------------  210.4/212.5 MB 165.0 MB/s eta 0:00:01\n",
      "   -------------------------------------  210.4/212.5 MB 165.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 212.5/212.5 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 138.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 133.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 133.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 133.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 36.6 MB/s eta 0:00:00\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "   ---------------------------------------- 0.0/194.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 194.4/194.4 kB 5.9 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, fsspec, filelock, torch\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.3.2 sympy-1.14.0 torch-2.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'C:\\Users\\896038\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\896038\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94554f72-8c71-4e15-9231-3eda2bae8c40",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsutil\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import psutil\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Starting environment setup...\")\n",
    "\n",
    "def check_environment():\n",
    "    print(\"\\n=== GPU Information ===\")\n",
    "    print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "    print(\"\\n=== System Memory ===\")\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Total: {memory.total / 1e9:.2f} GB\")\n",
    "    print(f\"Available: {memory.available / 1e9:.2f} GB\")\n",
    "    \n",
    "    print(\"\\n=== Python Environment ===\")\n",
    "    print(f\"Python Version: {sys.version}\")\n",
    "\n",
    "def create_project_structure():\n",
    "    BASE_DIR = \"uk_construction_bot\"\n",
    "    directories = [\n",
    "        'data/raw/videos',\n",
    "        'data/raw/documents',\n",
    "        'data/processed/embeddings',\n",
    "        'data/processed/summaries',\n",
    "        'data/processed/evaluations',  # For RAGAS and Giskard evaluations\n",
    "        'models/checkpoints',\n",
    "        'config'\n",
    "    ]\n",
    "    \n",
    "    for dir_path in directories:\n",
    "        path = os.path.join(BASE_DIR, dir_path)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        print(f\"Created directory: {path}\")\n",
    "    return BASE_DIR\n",
    "\n",
    "def create_config(base_dir):\n",
    "    config = {\n",
    "        'project': {\n",
    "            'name': 'uk_construction_bot',\n",
    "            'description': 'UK Construction Guidance Chatbot using RAG',\n",
    "            'version': '1.0'\n",
    "        },\n",
    "        'data_collection': {\n",
    "            'document_sources': [\n",
    "                \"https://www.gov.uk/government/collections/approved-documents\"\n",
    "            ],\n",
    "            'unstructured_config': {\n",
    "                'strategy': 'fast',\n",
    "                'include_metadata': True\n",
    "            }\n",
    "        },\n",
    "        'models': {\n",
    "            'embedding': 'sentence-transformers/all-mpnet-base-v2',\n",
    "        },\n",
    "        'processing': {\n",
    "            'chunk_size': 512,\n",
    "            'chunk_overlap': 50,\n",
    "            'min_chunk_length': 100,\n",
    "            'summary_max_length': 150,\n",
    "            'embedding_batch_size': 32\n",
    "        },\n",
    "        'vector_store': {\n",
    "            'engine': 'chroma',\n",
    "            'dimension': 768,\n",
    "            'distance_metric': 'cosine'\n",
    "        },\n",
    "        'evaluation': {\n",
    "            'ragas_metrics': [\n",
    "                'faithfulness',\n",
    "                'answer_relevancy',\n",
    "                'context_relevancy'\n",
    "            ],\n",
    "            'batch_size': 5\n",
    "        }\n",
    "    }\n",
    "\n",
    "    config_path = os.path.join(base_dir, 'config', 'config.yaml')\n",
    "    with open(config_path, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)\n",
    "    print(f\"Configuration file created at: {config_path}\")\n",
    "    return config\n",
    "\n",
    "def install_dependencies():\n",
    "    \"\"\"Install required packages with better error handling\"\"\"\n",
    "    base_packages = [\n",
    "        \"transformers==4.36.0\",\n",
    "        \"sentence-transformers==2.2.2\",\n",
    "        \"chromadb==0.4.0\",\n",
    "        \"tqdm==4.66.1\"\n",
    "    ]\n",
    "    \n",
    "    document_packages = [\n",
    "        \"unstructured[pdf,local-inference]\",\n",
    "        \"pdf2image\",\n",
    "        \"pdfminer.six\",\n",
    "        \"python-magic-bin; platform_system=='Windows'\"\n",
    "    ]\n",
    "    \n",
    "    evaluation_packages = [\n",
    "        \"ragas==0.0.22\",\n",
    "        \"evaluate\",\n",
    "    ]\n",
    "    \n",
    "    utility_packages = [\n",
    "        \"python-dotenv==1.0.0\",\n",
    "        \"beautifulsoup4==4.12.2\",\n",
    "        \"requests==2.31.0\"\n",
    "    ]\n",
    "    \n",
    "    def install_package_group(packages, group_name):\n",
    "        print(f\"\\nInstalling {group_name}...\")\n",
    "        for package in packages:\n",
    "            try:\n",
    "                print(f\"Installing {package}\")\n",
    "                result = os.system(f\"pip install -q {package}\")\n",
    "                if result == 0:\n",
    "                    print(f\"Successfully installed {package}\")\n",
    "                else:\n",
    "                    print(f\"Failed to install {package}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error installing {package}: {str(e)}\")\n",
    "    \n",
    "    # Install in sequence\n",
    "    install_package_group(base_packages, \"base packages\")\n",
    "    install_package_group(utility_packages, \"utility packages\")\n",
    "    install_package_group(document_packages, \"document processing packages\")\n",
    "    install_package_group(evaluation_packages, \"evaluation packages\")\n",
    "    \n",
    "    # Verify installations\n",
    "    def verify_package(package_name):\n",
    "        try:\n",
    "            __import__(package_name)\n",
    "            return True\n",
    "        except ImportError:\n",
    "            return False\n",
    "    \n",
    "    print(\"\\nVerifying critical packages:\")\n",
    "    critical_packages = {\n",
    "        'unstructured': 'Document processing',\n",
    "        'ragas': 'RAG evaluation',\n",
    "        'transformers': 'Transformers',\n",
    "        'chromadb': 'Vector store'\n",
    "    }\n",
    "    \n",
    "    all_verified = True\n",
    "    for package, description in critical_packages.items():\n",
    "        if verify_package(package):\n",
    "            print(f\"✓ {description} successfully installed\")\n",
    "        else:\n",
    "            print(f\"✗ {description} not installed correctly\")\n",
    "            all_verified = False\n",
    "    \n",
    "    return all_verified\n",
    "\n",
    "def setup_env_file(base_dir):\n",
    "    env_path = os.path.join(base_dir, '.env')\n",
    "    if not os.path.exists(env_path):\n",
    "        with open(env_path, 'w') as f:\n",
    "            f.write('GROQ_API_KEY=your-groq-key-here\\n')\n",
    "    print(f\"Created .env file at: {env_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"Checking environment...\")\n",
    "        check_environment()\n",
    "\n",
    "        print(\"\\nCreating project structure...\")\n",
    "        base_dir = create_project_structure()\n",
    "\n",
    "        print(\"\\nCreating configuration file...\")\n",
    "        config = create_config(base_dir)\n",
    "\n",
    "        print(\"\\nSetting up environment file...\")\n",
    "        setup_env_file(base_dir)\n",
    "\n",
    "        print(\"\\nInstalling dependencies...\")\n",
    "        if install_dependencies():\n",
    "            print(\"\\nAll dependencies installed successfully!\")\n",
    "        else:\n",
    "            print(\"\\nSome dependencies need manual installation. Please run:\")\n",
    "            print(\"pip install 'unstructured[pdf]'\")\n",
    "            print(\"pip install ragas\")\n",
    "\n",
    "        # Verify setup\n",
    "        config_path = os.path.join(base_dir, 'config', 'config.yaml')\n",
    "        with open(config_path, 'r') as f:\n",
    "            loaded_config = yaml.safe_load(f)\n",
    "        print(\"\\nConfiguration loaded successfully!\")\n",
    "        \n",
    "        print(\"\\nSetup complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during setup: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a5366-71e7-45ee-bb2e-d92d29190390",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866de5ef-4c4b-4510-b673-aec12c2b2c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: unstructured-client in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (0.30.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pydantic in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (2.10.6)\n",
      "Requirement already satisfied: langchain in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (0.3.18)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (0.3.17)\n",
      "Requirement already satisfied: langchain_core in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (0.3.35)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (0.3.5)\n",
      "Requirement already satisfied: chromadb in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (0.6.3)\n",
      "Requirement already satisfied: unstructured[all-docs] in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (0.16.20)\n",
      "Requirement already satisfied: chardet in c:\\program files\\python312\\lib\\site-packages (from unstructured[all-docs]) (5.2.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (0.4.27)\n",
      "Requirement already satisfied: lxml in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (5.3.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (3.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\program files\\python312\\lib\\site-packages (from unstructured[all-docs]) (4.12.3)\n",
      "Requirement already satisfied: emoji in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (2.14.1)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (2025.2.8)\n",
      "Requirement already satisfied: langdetect in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (1.0.9)\n",
      "Requirement already satisfied: numpy<2 in c:\\program files\\python312\\lib\\site-packages (from unstructured[all-docs]) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (3.12.1)\n",
      "Requirement already satisfied: backoff in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (4.12.2)\n",
      "Requirement already satisfied: wrapt in c:\\program files\\python312\\lib\\site-packages (from unstructured[all-docs]) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\program files\\python312\\lib\\site-packages (from unstructured[all-docs]) (5.9.8)\n",
      "Requirement already satisfied: python-oxmsg in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (0.0.2)\n",
      "Requirement already satisfied: html5lib in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (1.1)\n",
      "Requirement already satisfied: pandas in c:\\program files\\python312\\lib\\site-packages (from unstructured[all-docs]) (2.2.2)\n",
      "Requirement already satisfied: unstructured-inference>=0.8.6 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (0.8.7)\n",
      "Requirement already satisfied: python-docx>=1.1.2 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (1.1.2)\n",
      "Requirement already satisfied: onnx in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (1.17.0)\n",
      "Requirement already satisfied: python-pptx>=1.0.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (1.0.2)\n",
      "Requirement already satisfied: xlrd in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (2.0.1)\n",
      "Requirement already satisfied: markdown in c:\\program files\\python312\\lib\\site-packages (from unstructured[all-docs]) (3.6)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (3.1.5)\n",
      "Requirement already satisfied: effdet in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (0.4.1)\n",
      "Requirement already satisfied: networkx in c:\\program files\\python312\\lib\\site-packages (from unstructured[all-docs]) (3.3)\n",
      "Requirement already satisfied: google-cloud-vision in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (3.10.0)\n",
      "Requirement already satisfied: pi-heif in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (0.21.0)\n",
      "Requirement already satisfied: pypandoc in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (1.15)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (20240706)\n",
      "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (0.3.13)\n",
      "Requirement already satisfied: pikepdf in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (9.5.2)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (1.17.0)\n",
      "Requirement already satisfied: pypdf in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured[all-docs]) (5.3.0)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured-client) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\program files\\python312\\lib\\site-packages (from unstructured-client) (42.0.5)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured-client) (0.2.2)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\program files\\python312\\lib\\site-packages (from unstructured-client) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\program files\\python312\\lib\\site-packages (from unstructured-client) (1.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\program files\\python312\\lib\\site-packages (from unstructured-client) (2.9.0.post0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured-client) (1.0.0)\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured-client) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python312\\lib\\site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from pydantic) (2.27.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\program files\\python312\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\program files\\python312\\lib\\site-packages (from langchain_core) (24.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain_openai) (1.63.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (0.115.8)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (3.13.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\program files\\python312\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (1.70.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\program files\\python312\\lib\\site-packages (from chromadb) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\program files\\python312\\lib\\site-packages (from chromadb) (0.9.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (32.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\program files\\python312\\lib\\site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\program files\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python312\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\program files\\python312\\lib\\site-packages (from cryptography>=3.1->unstructured-client) (1.16.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json->unstructured[all-docs]) (3.26.1)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n",
      "Requirement already satisfied: anyio in c:\\program files\\python312\\lib\\site-packages (from httpx>=0.27.0->unstructured-client) (4.3.0)\n",
      "Requirement already satisfied: certifi in c:\\program files\\python312\\lib\\site-packages (from httpx>=0.27.0->unstructured-client) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\program files\\python312\\lib\\site-packages (from httpx>=0.27.0->unstructured-client) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\program files\\python312\\lib\\site-packages (from httpx>=0.27.0->unstructured-client) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\program files\\python312\\lib\\site-packages (from httpx>=0.27.0->unstructured-client) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\program files\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\program files\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\program files\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\program files\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\program files\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\program files\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\program files\\python312\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\program files\\python312\\lib\\site-packages (from python-pptx>=1.0.1->unstructured[all-docs]) (10.3.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from python-pptx>=1.0.1->unstructured[all-docs]) (3.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python312\\lib\\site-packages (from requests->unstructured[all-docs]) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\program files\\python312\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\program files\\python312\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\program files\\python312\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\program files\\python312\\lib\\site-packages (from typing-inspect>=0.9.0->unstructured-client) (1.0.0)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured-inference>=0.8.6->unstructured[all-docs]) (0.0.20)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in c:\\program files\\python312\\lib\\site-packages (from unstructured-inference>=0.8.6->unstructured[all-docs]) (4.9.0.80)\n",
      "Requirement already satisfied: matplotlib in c:\\program files\\python312\\lib\\site-packages (from unstructured-inference>=0.8.6->unstructured[all-docs]) (3.8.4)\n",
      "Requirement already satisfied: torch in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured-inference>=0.8.6->unstructured[all-docs]) (2.6.0)\n",
      "Requirement already satisfied: timm in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured-inference>=0.8.6->unstructured[all-docs]) (1.0.14)\n",
      "Requirement already satisfied: transformers>=4.25.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured-inference>=0.8.6->unstructured[all-docs]) (4.48.3)\n",
      "Requirement already satisfied: scipy in c:\\program files\\python312\\lib\\site-packages (from unstructured-inference>=0.8.6->unstructured[all-docs]) (1.11.4)\n",
      "Requirement already satisfied: pypdfium2 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from unstructured-inference>=0.8.6->unstructured[all-docs]) (4.30.1)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\program files\\python312\\lib\\site-packages (from beautifulsoup4->unstructured[all-docs]) (2.5)\n",
      "Requirement already satisfied: torchvision in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from effdet->unstructured[all-docs]) (0.21.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from effdet->unstructured[all-docs]) (2.0.8)\n",
      "Requirement already satisfied: omegaconf>=2.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from effdet->unstructured[all-docs]) (2.3.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (2.24.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-vision->unstructured[all-docs]) (1.26.0)\n",
      "Requirement already satisfied: webencodings in c:\\program files\\python312\\lib\\site-packages (from html5lib->unstructured[all-docs]) (0.5.1)\n",
      "Requirement already satisfied: joblib in c:\\program files\\python312\\lib\\site-packages (from nltk->unstructured[all-docs]) (1.4.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from openpyxl->unstructured[all-docs]) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python312\\lib\\site-packages (from pandas->unstructured[all-docs]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\program files\\python312\\lib\\site-packages (from pandas->unstructured[all-docs]) (2024.1)\n",
      "Requirement already satisfied: olefile in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from python-oxmsg->unstructured[all-docs]) (0.47)\n",
      "Requirement already satisfied: pycparser in c:\\program files\\python312\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client) (2.22)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.70.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\program files\\python312\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\program files\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from omegaconf>=2.0->effdet->unstructured[all-docs]) (4.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\program files\\python312\\lib\\site-packages (from matplotlib->unstructured-inference>=0.8.6->unstructured[all-docs]) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\python312\\lib\\site-packages (from matplotlib->unstructured-inference>=0.8.6->unstructured[all-docs]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\program files\\python312\\lib\\site-packages (from matplotlib->unstructured-inference>=0.8.6->unstructured[all-docs]) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\program files\\python312\\lib\\site-packages (from matplotlib->unstructured-inference>=0.8.6->unstructured[all-docs]) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\program files\\python312\\lib\\site-packages (from matplotlib->unstructured-inference>=0.8.6->unstructured[all-docs]) (3.1.2)\n",
      "Requirement already satisfied: safetensors in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from timm->unstructured-inference>=0.8.6->unstructured[all-docs]) (0.5.2)\n",
      "Requirement already satisfied: jinja2 in c:\\program files\\python312\\lib\\site-packages (from torch->unstructured-inference>=0.8.6->unstructured[all-docs]) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python312\\lib\\site-packages (from torch->unstructured-inference>=0.8.6->unstructured[all-docs]) (69.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\program files\\python312\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\python312\\lib\\site-packages (from jinja2->torch->unstructured-inference>=0.8.6->unstructured[all-docs]) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install \"unstructured[all-docs]\" unstructured-client python-dotenv pydantic langchain langchain-community langchain_core langchain_openai chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e11dd0f4-6b90-479d-b13d-8248967ec3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-groq in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (0.2.4)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (3.4.1)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain-groq) (0.18.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain-groq) (0.3.35)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.48.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\program files\\python312\\lib\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\program files\\python312\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in c:\\program files\\python312\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\program files\\python312\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\program files\\python312\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from groq<1,>=0.4.1->langchain-groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\program files\\python312\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\program files\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\program files\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.33)\n",
      "Requirement already satisfied: networkx in c:\\program files\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\program files\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\program files\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python312\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\program files\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\program files\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\program files\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\program files\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\program files\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\program files\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\program files\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-groq sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abc67fa0-69e2-40a3-8444-eec42d17b2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tf-keras in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\program files\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\896038\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\program files\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\program files\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\program files\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\program files\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\program files\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\program files\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\program files\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\program files\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\program files\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\program files\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\program files\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59233cee-a0e0-4937-93f0-cd32f7900744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 10.2/992.0 kB ? eta -:--:--\n",
      "    -------------------------------------- 20.5/992.0 kB 640.0 kB/s eta 0:00:02\n",
      "   - ------------------------------------- 41.0/992.0 kB 653.6 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 143.4/992.0 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 286.7/992.0 kB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 583.7/992.0 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  983.0/992.0 kB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 992.0/992.0 kB 4.5 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbac6ccf-9d66-48a4-a836-cc8518e60c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\896038.adir\\appdata\\roaming\\python\\python312\\site-packages (3.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pycryptodome in c:\\users\\896038.adir\\appdata\\roaming\\python\\python312\\site-packages (3.22.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n",
    "!pip install pycryptodome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1838d55-45fe-4aec-973f-9e115c4bbd6b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c6e0228-bac3-489f-a6e6-ceac954fb6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "from PyPDF2.errors import PdfReadError\n",
    "#import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd2c002-9258-4ae6-b67b-dbb58e127b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Total GOV.UK PDFs loaded: 18\n",
      "Loading Comprehensive UK Building Regulations Files:\n",
      "1. approved-document-R_Infrastructure_Electronic_communications.pdf\n",
      "2. approved-document_P_Electrical_Safety.pdf\n",
      "3. approved-document_Q_Security in Dwellings.pdf\n",
      "4. ApprovedDocument_T Toilet accommodation.pdf\n",
      "5. approved_document_A_Structure.pdf\n",
      "6. Approved_Document_B_Fire_safety.pdf\n",
      "7. Approved_Document_C_site preparation and resistance to contaminates and moisture.pdf\n",
      "8. approved_document_D_Toxic Substance.pdf\n",
      "9. approved_document_E_Resistance to sound.pdf\n",
      "10. approved_document_F_Ventilation.pdf\n",
      "11. approved_document_G_Sanitation, hot water safety and water efficiency.pdf\n",
      "12. approved_document_H_Drainage and waste disposal.pdf\n",
      "13. approved_document_J_Combustion appliances and fuel storage systems.pdf\n",
      "14. Approved_Document_K_Protection from falling, collision and impact.pdf\n",
      "15. approved_document_L_Conservation of fuel and power.pdf\n",
      "16. approved_document_M_Access to and use of buildings.pdf\n",
      "17. approved_document_O_Overheating.pdf\n",
      "18. Approved_Document_S_Infrastructure for charging electric vehicles.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_dir = Path(\"uk_construction_bot/data/raw/documents/gov_uk_building_regulations_PDFs\")\n",
    "pdf_files = list(pdf_dir.glob(\"*.pdf\"))\n",
    "\n",
    "print(f\"\\n✅ Total GOV.UK PDFs loaded: {len(pdf_files)}\")\n",
    "print(\"Loading Comprehensive UK Building Regulations Files:\")\n",
    "for i, pdf_file in enumerate(pdf_files, start=1):\n",
    "    print(f\"{i}. {pdf_file.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc1c305-4fca-4ed1-b641-990a9584bba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Counting pages in: uk_construction_bot/data/raw/documents/gov_uk_building_regulations_PDFs\n",
      "📄 approved-document-R_Infrastructure_Electronic_communications.pdf: 20 pages\n",
      "📄 approved-document_P_Electrical_Safety.pdf: 22 pages\n",
      "📄 approved-document_Q_Security in Dwellings.pdf: 20 pages\n",
      "📄 ApprovedDocument_T Toilet accommodation.pdf: 36 pages\n",
      "📄 approved_document_A_Structure.pdf: 54 pages\n",
      "📄 Approved_Document_B_Fire_safety.pdf: 22 pages\n",
      "📄 Approved_Document_C_site preparation and resistance to contaminates and moisture.pdf: 52 pages\n",
      "📄 approved_document_D_Toxic Substance.pdf: 10 pages\n",
      "📄 approved_document_E_Resistance to sound.pdf: 86 pages\n",
      "📄 approved_document_F_Ventilation.pdf: 62 pages\n",
      "📄 approved_document_G_Sanitation, hot water safety and water efficiency.pdf: 56 pages\n",
      "📄 approved_document_H_Drainage and waste disposal.pdf: 64 pages\n",
      "📄 approved_document_J_Combustion appliances and fuel storage systems.pdf: 89 pages\n",
      "📄 Approved_Document_K_Protection from falling, collision and impact.pdf: 68 pages\n",
      "📄 approved_document_L_Conservation of fuel and power.pdf: 104 pages\n",
      "📄 approved_document_M_Access to and use of buildings.pdf: 74 pages\n",
      "📄 approved_document_O_Overheating.pdf: 44 pages\n",
      "📄 Approved_Document_S_Infrastructure for charging electric vehicles.pdf: 47 pages\n",
      "\n",
      "✅ Total PDFs found: 18\n",
      "📘 Successfully read PDFs: 18\n",
      "🧾 Total pages across all readable PDFs: 930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "930"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_pages_in_directory(directory_path):\n",
    "    \"\"\"Count the total number of pages across all readable PDF files in a directory\"\"\"\n",
    "    total_pages = 0\n",
    "    file_count = 0\n",
    "    total_files = 0\n",
    "    \n",
    "    print(\"📁 Counting pages in:\", directory_path)\n",
    "    \n",
    "    for pdf_file in Path(directory_path).glob(\"*.pdf\"):\n",
    "        total_files += 1\n",
    "        try:\n",
    "            reader = PdfReader(str(pdf_file))\n",
    "\n",
    "            if reader.is_encrypted:\n",
    "                try:\n",
    "                    reader.decrypt(\"\")  # Try blank password\n",
    "                except:\n",
    "                    raise PdfReadError(\"Encrypted and couldn't decrypt.\")\n",
    "\n",
    "            num_pages = len(reader.pages)\n",
    "            total_pages += num_pages\n",
    "            file_count += 1\n",
    "            print(f\"📄 {pdf_file.name}: {num_pages} pages\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Error reading {pdf_file.name}: {e}\")\n",
    "    \n",
    "    print(f\"\\n✅ Total PDFs found: {total_files}\")\n",
    "    print(f\"📘 Successfully read PDFs: {file_count}\")\n",
    "    print(f\"🧾 Total pages across all readable PDFs: {total_pages}\")\n",
    "    return total_pages\n",
    "\n",
    "pdf_folder = \"uk_construction_bot/data/raw/documents/gov_uk_building_regulations_PDFs\"\n",
    "count_pages_in_directory(pdf_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c324aff-0f4a-4732-a5ae-9b4160509839",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating Embeddings and Vector Store to Utilize in RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d1082-f655-4a18-9ade-d2a811a2b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Any, List, Optional\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import torch\n",
    "\n",
    "#Importing Unstructured components\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured_client import UnstructuredClient\n",
    "from unstructured_client.models import shared\n",
    "from unstructured_client.models.errors import SDKError\n",
    "from unstructured.staging.base import dict_to_elements\n",
    "from unstructured_client.models.operations.partition import PartitionRequest\n",
    "\n",
    "#Importing LangChain components\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.schema.document import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eb7abe-37ad-4ff1-90ed-4880d8341360",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Element(BaseModel):\n",
    "    #Basic data wrapper to store type and content of each document chunk\n",
    "    type: str\n",
    "    page_content: Any\n",
    "\n",
    "class GroqHandler:\n",
    "    def __init__(self, api_key: str, model_name: str = \"llama-3.3-70b-versatile\"):\n",
    "        #Initialize Groq LLM with streaming and no randomness\n",
    "        self.llm = ChatGroq(\n",
    "            api_key=api_key,\n",
    "            model_name=model_name,\n",
    "            temperature=0.1,\n",
    "            streaming=True,\n",
    "            callbacks=[StreamingStdOutCallbackHandler()]\n",
    "        )\n",
    "        \n",
    "        # self.template = \"\"\"You are an expert assistant specializing in UK construction regulations and building codes. Your task is to provide accurate, clear answers based solely on the provided context.\n",
    "\n",
    "        # Approach:\n",
    "        # 1. Analyze the provided context carefully\n",
    "        # 2. If the answer is found in the context, provide it with specific references\n",
    "        # 3. If tables or technical specifications are mentioned, include them\n",
    "        # 4. If the answer cannot be found in the context, explicitly state this\n",
    "        # 5. If details are unclear, mention this in your response\n",
    "\n",
    "        # Context: {context}\n",
    "        \n",
    "        # Question: {question}\n",
    "        \n",
    "        # Answer the question step by step:\"\"\"\n",
    "\n",
    "        #Defining prompt template\n",
    "        self.template = \"\"\"Answer the question based only on the following context, which can include text and tables:\n",
    "        {context}\n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "\n",
    "        self.prompt = ChatPromptTemplate.from_template(self.template)\n",
    "\n",
    "        #Build LangChain chain with LLM and output parser\n",
    "        self.chain = (\n",
    "            self.prompt \n",
    "            | self.llm \n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    def generate_answer(self, context: str, question: str, max_retries: int = 3) -> Optional[str]:\n",
    "        \"\"\"Generate answer with retry logic and error handling\"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                print(\"\\nGenerating response (streaming)...\")\n",
    "                response = self.chain.invoke({\n",
    "                    \"context\": context,\n",
    "                    \"question\": question\n",
    "                })\n",
    "                return response\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    print(f\"\\nError: Failed to generate answer after {max_retries} attempts: {str(e)}\")\n",
    "                    return None\n",
    "                print(f\"\\nAttempt {attempt + 1} failed, retrying in {2 ** attempt} seconds...\")\n",
    "                time.sleep(2 ** attempt)  #Exponential backoff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c865c18-657c-4a2f-9444-7b0cadca4fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self\n",
    "                #Initialize Unstructured API and HuggingFace embeddings\n",
    "        self.client = UnstructuredClient(\n",
    "            api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\"), #reading UNSTRUCTURED_API_KEY from .evn \n",
    "            server_url=os.getenv(\"UNSTRUCTURED_API_URL\")\n",
    "        )\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "            model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'}\n",
    "        )\n",
    "        \n",
    "        self.setup_rag_components()\n",
    "        \n",
    "    def setup_rag_components(self):\n",
    "        \"\"\"Initialize RAG components\"\"\"\n",
    "        #Initialize vector store and docstore for retrieval\n",
    "        self.store = InMemoryStore()\n",
    "        self.vectorstore = Chroma(\n",
    "            collection_name=\"main_construction_rag\",\n",
    "            embedding_function=self.embeddings,\n",
    "            persist_directory=\"./main_chroma_data\",\n",
    "        )\n",
    "        self.retriever = MultiVectorRetriever(\n",
    "            vectorstore=self.vectorstore,\n",
    "            docstore=self.store,\n",
    "            id_key=\"doc_id\",\n",
    "        )\n",
    "    \n",
    "    def save_processed_elements(self, elements: List[Element], filename: str):\n",
    "        \"\"\"Save processed elements to avoid reprocessing\"\"\"\n",
    "        save_data = [{\"type\": el.type, \"page_content\": el.page_content} for el in elements]\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(save_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"\\nSaved {len(elements)} elements to {filename}\")\n",
    "        \n",
    "    def load_processed_elements(self, filename: str) -> List[Element]:\n",
    "        \"\"\"Load previously processed elements\"\"\"\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            elements = [Element(**item) for item in data]\n",
    "            print(f\"\\nLoaded {len(elements)} elements from {filename}\")\n",
    "            return elements\n",
    "        return []\n",
    "\n",
    "    def process_pdf_with_cache(self, pdf_path: str, cache_dir: str = \"processed_cache\"):\n",
    "        \"\"\"Process PDF with caching\"\"\"\n",
    "        #Create cache directory if it doesn't exist\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        \n",
    "        #Generate cache filename based on PDF name\n",
    "        pdf_name = Path(pdf_path).stem\n",
    "        cache_file = os.path.join(cache_dir, f\"{pdf_name}_processed.json\")\n",
    "        \n",
    "        #Check if cached version exists\n",
    "        if os.path.exists(cache_file):\n",
    "            print(f\"\\nLoading cached version of {pdf_path}...\")\n",
    "            return self.load_processed_elements(cache_file)\n",
    "            \n",
    "        #If no cache, process normally\n",
    "        elements = self.process_pdf(pdf_path)\n",
    "        if elements:\n",
    "            print(f\"\\nCaching processed elements for {pdf_path}...\")\n",
    "            self.save_processed_elements(elements, cache_file)\n",
    "        return elements\n",
    "\n",
    "    def process_pdf(self, pdf_path: str):\n",
    "        \"\"\"Process PDF using Unstructured API\"\"\"\n",
    "        try:\n",
    "            print(f\"\\nProcessing {pdf_path}...\")\n",
    "            \n",
    "            with open(pdf_path, \"rb\") as f:\n",
    "                files = shared.Files(\n",
    "                    content=f.read(),\n",
    "                    file_name=pdf_path\n",
    "                )\n",
    "            \n",
    "            partition_params = shared.PartitionParameters(\n",
    "                files=files,\n",
    "                strategy=\"hi_res\",\n",
    "                hi_res_model_name=\"yolox\",\n",
    "                skip_infer_table_types=[],\n",
    "                pdf_infer_table_structure=True\n",
    "            )\n",
    "            \n",
    "            req = PartitionRequest(partition_parameters=partition_params)\n",
    "            elements = self.client.general.partition(request=req).elements\n",
    "            api_elements = dict_to_elements(elements)\n",
    "            \n",
    "            categorized_elements = []\n",
    "            for element in api_elements:\n",
    "                if \"Table\" in str(type(element)):\n",
    "                    categorized_elements.append(Element(\n",
    "                        type=\"table\",\n",
    "                        page_content=str(element.metadata.text_as_html)\n",
    "                    ))\n",
    "                elif any(t in str(type(element)) for t in [\"NarrativeText\", \"Title\", \"ListItem\"]):\n",
    "                    categorized_elements.append(Element(\n",
    "                        type=\"text\",\n",
    "                        page_content=str(element)\n",
    "                    ))\n",
    "            \n",
    "            print(f\"Successfully processed with {len(categorized_elements)} elements\")\n",
    "            return categorized_elements\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing PDF: {e}\")\n",
    "            return []\n",
    "\n",
    "    def process_youtube_data(self, csv_path: str):\n",
    "        \"\"\"Process YouTube transcript data\"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        elements = []\n",
    "        for _, row in df.iterrows():\n",
    "            elements.append(Element(\n",
    "                type=\"text\",\n",
    "                page_content=row['content']\n",
    "            ))\n",
    "        return elements\n",
    "\n",
    "    def setup_retrieval_system(self, elements: List[Element]):\n",
    "        \"\"\"Set up multi-vector retrieval system with DistilBART summarization\"\"\"\n",
    "        from transformers import pipeline\n",
    "        import torch\n",
    "        \n",
    "        #Separate elements by type\n",
    "        table_elements = [el for el in elements if el.type == \"table\"]\n",
    "        text_elements = [el for el in elements if el.type == \"text\"]\n",
    "        \n",
    "        #Defining batch sizes\n",
    "        CHROMA_BATCH_SIZE = 5000   #Max number of elements to process per batch when adding to Chroma vector store\n",
    "        SUMMARY_BATCH_SIZE = 8    #Number of text chunks to summarize at once with the DistilBART model\n",
    "\n",
    "        def generate_summaries_batch(texts: List[str]) -> List[str]:\n",
    "            \"\"\"Generate summaries using DistilBART in batches\"\"\"\n",
    "            try:\n",
    "                if not hasattr(self, 'summarizer'):\n",
    "                    print(\"\\nInitializing DistilBART summarizer...\")\n",
    "                    self.summarizer = pipeline(\n",
    "                        \"summarization\",\n",
    "                        model=\"sshleifer/distilbart-cnn-12-6\",\n",
    "                        device=0 if torch.cuda.is_available() else -1,\n",
    "                        batch_size=SUMMARY_BATCH_SIZE\n",
    "                    )\n",
    "                \n",
    "                print(f\"Generating summaries for {len(texts)} texts...\")\n",
    "                summaries = []\n",
    "                \n",
    "                #Process in smaller batches\n",
    "                for i in range(0, len(texts), SUMMARY_BATCH_SIZE):\n",
    "                    batch = texts[i:i + SUMMARY_BATCH_SIZE]\n",
    "                    print(f\"Processing summary batch {i//SUMMARY_BATCH_SIZE + 1}/{len(texts)//SUMMARY_BATCH_SIZE + 1}\")\n",
    "                    \n",
    "                    #Check summary cache\n",
    "                    cache_file = f\"summary_cache/batch_{i}.json\"\n",
    "                    if os.path.exists(cache_file):\n",
    "                        with open(cache_file, 'r', encoding='utf-8') as f:\n",
    "                            batch_summaries = json.load(f)\n",
    "                        print(f\"Loaded {len(batch_summaries)} summaries from cache\")\n",
    "                    else:\n",
    "                        #Adjust max_length based on input length\n",
    "                        max_input_length = max(len(text.split()) for text in batch)\n",
    "                        max_summary_length = min(150, max(40, max_input_length // 2))\n",
    "                        \n",
    "                        #Generate new summaries\n",
    "                        batch_summaries = self.summarizer(\n",
    "                            batch,\n",
    "                            max_length=max_summary_length,\n",
    "                            min_length=min(30, max_summary_length - 10),\n",
    "                            do_sample=False\n",
    "                        )\n",
    "                        batch_summaries = [s['summary_text'] for s in batch_summaries]\n",
    "                        \n",
    "                        #Cache the summaries\n",
    "                        os.makedirs(\"summary_cache\", exist_ok=True)\n",
    "                        with open(cache_file, 'w', encoding='utf-8') as f:\n",
    "                            json.dump(batch_summaries, f, ensure_ascii=False, indent=2)\n",
    "                    \n",
    "                    summaries.extend(batch_summaries)\n",
    "                \n",
    "                return summaries\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error in summary generation: {e}\")\n",
    "                return [text[:200] for text in texts]  # Fallback to truncation\n",
    "\n",
    "        def process_in_batches(elements_list, element_type: str):\n",
    "            \"\"\"Process elements in batches with multi-vector storage\"\"\"\n",
    "            #Embed full and summarized documents into vectorstore for efficient retrival \n",
    "            for i in range(0, len(elements_list), CHROMA_BATCH_SIZE):\n",
    "                batch = elements_list[i:i + CHROMA_BATCH_SIZE]\n",
    "                print(f\"\\nProcessing {element_type} batch {i//CHROMA_BATCH_SIZE + 1}/{len(elements_list)//CHROMA_BATCH_SIZE + 1}\")\n",
    "                \n",
    "                #Generate IDs for batch\n",
    "                batch_ids = [str(uuid.uuid4()) for _ in batch]\n",
    "                \n",
    "                #Generate summaries for the batch\n",
    "                summaries = generate_summaries_batch([el.page_content for el in batch])\n",
    "                \n",
    "                try:\n",
    "                    #Create documents for both full content and summaries\n",
    "                    full_docs = []\n",
    "                    summary_docs = []\n",
    "                    \n",
    "                    for idx, (element, summary) in enumerate(zip(batch, summaries)):\n",
    "                        #Add full content document\n",
    "                        full_docs.append(Document(\n",
    "                            page_content=element.page_content,\n",
    "                            metadata={\n",
    "                                \"doc_id\": batch_ids[idx],\n",
    "                                \"type\": element_type,\n",
    "                                \"version\": \"full\"\n",
    "                            }\n",
    "                        ))\n",
    "                        \n",
    "                        #Add summary document\n",
    "                        summary_docs.append(Document(\n",
    "                            page_content=summary,\n",
    "                            metadata={\n",
    "                                \"doc_id\": batch_ids[idx],\n",
    "                                \"type\": element_type,\n",
    "                                \"version\": \"summary\"\n",
    "                            }\n",
    "                        ))\n",
    "                    \n",
    "                    #Add to vectorstore\n",
    "                    if full_docs and summary_docs:\n",
    "                        print(\"Adding documents to vectorstore...\")\n",
    "                        self.retriever.vectorstore.add_documents(full_docs)\n",
    "                        self.retriever.vectorstore.add_documents(summary_docs)\n",
    "                        \n",
    "                        #Store original elements\n",
    "                        self.retriever.docstore.mset(list(zip(batch_ids, batch)))\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing batch: {e}\")\n",
    "                    continue\n",
    "\n",
    "        \n",
    "        \n",
    "        #Process elements by type\n",
    "        if table_elements:\n",
    "            print(f\"\\nProcessing {len(table_elements)} table elements...\")\n",
    "            process_in_batches(table_elements, \"table\")\n",
    "        \n",
    "        if text_elements:\n",
    "            print(f\"\\nProcessing {len(text_elements)} text elements...\")\n",
    "            process_in_batches(text_elements, \"text\")\n",
    "        \n",
    "        #Persist the vectorstore\n",
    "        print(\"\\nPersisting vectorstore...\")\n",
    "        self.vectorstore.persist()\n",
    "        \n",
    "        print(\"\\nMulti-vector retrieval system setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3cd229-c08e-4fb6-ab1e-27494dbffee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\896038\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\896038\\AppData\\Roaming\\Python\\Python312\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (2022server). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n",
      "C:\\Users\\896038\\AppData\\Local\\Temp\\ipykernel_23612\\592434953.py:97: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings = HuggingFaceEmbeddings(\n",
      "WARNING: From C:\\Users\\896038\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "INFO: PyTorch version 2.6.0 available.\n",
      "INFO: TensorFlow version 2.18.0 available.\n",
      "INFO: Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "C:\\Users\\896038\\AppData\\Local\\Temp\\ipykernel_23612\\592434953.py:107: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  self.vectorstore = Chroma(\n",
      "INFO: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select data source:\n",
      "1. YouTube Transcripts\n",
      "2. PDF Documents\n",
      "3. Combined Data\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1-3):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading cached version of uk_construction_bot\\data\\raw\\documents\\approved_document_A.pdf...\n",
      "\n",
      "Loaded 1013 elements from processed_cache\\approved_document_A_processed.json\n",
      "\n",
      "Loading cached version of uk_construction_bot\\data\\raw\\documents\\Approved_Document_B__fire_safety__volume_1_-_Dwellings__2019_edition_incorporating_2020_and_2022_amendments_collated_with_2025__2026_and_2029_amendments.pdf...\n",
      "\n",
      "Loaded 3495 elements from processed_cache\\Approved_Document_B__fire_safety__volume_1_-_Dwellings__2019_edition_incorporating_2020_and_2022_amendments_collated_with_2025__2026_and_2029_amendments_processed.json\n",
      "\n",
      "Loading cached version of uk_construction_bot\\data\\raw\\documents\\approved_document_C.pdf...\n",
      "\n",
      "Loaded 1256 elements from processed_cache\\approved_document_C_processed.json\n",
      "\n",
      "Setting up retrieval system...\n",
      "\n",
      "Processing 75 table elements...\n",
      "\n",
      "Processing table batch 1/1\n",
      "\n",
      "Initializing DistilBART summarizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44f5daf78a24594a530d935e0183ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\896038\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\896038\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aedacca9ca348e38b7673cf174fc603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b52e05245f145a2817236cf4c3a079b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124701788f8e48988898ab5328556e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac766011c74f4f39b6c3c6f31127e0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7f24755fa34ffca95228455faceffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating summaries for 75 texts...\n",
      "Processing summary batch 1/10\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 2/10\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 3/10\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 4/10\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 5/10\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 6/10\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 7/10\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 8/10\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 9/10\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 10/10\n",
      "Loaded 8 summaries from cache\n",
      "Adding documents to vectorstore...\n",
      "\n",
      "Processing 5689 text elements...\n",
      "\n",
      "Processing text batch 1/2\n",
      "Generating summaries for 5000 texts...\n",
      "Processing summary batch 1/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 2/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 3/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 4/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 5/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 6/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 7/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 8/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 9/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 10/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 11/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 12/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 13/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 14/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 15/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 16/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 17/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 18/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 19/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 20/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 21/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 22/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 23/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 24/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 25/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 26/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 27/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 28/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 29/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 30/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 31/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 32/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 33/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 34/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 35/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 36/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 37/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 38/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 39/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 40/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 41/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 42/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 43/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 44/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 45/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 46/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 47/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 48/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 49/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 50/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 51/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 52/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 53/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 54/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 55/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 56/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 57/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 58/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 59/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 60/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 61/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 62/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 63/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 64/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 65/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 66/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 67/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 68/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 69/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 70/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 71/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 72/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 73/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 74/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 75/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 76/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 77/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 78/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 79/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 80/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 81/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 82/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 83/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 84/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 85/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 86/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 87/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 88/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 89/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 90/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 91/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 92/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 93/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 94/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 95/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 96/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 97/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 98/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 99/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 100/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 101/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 102/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 103/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 104/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 105/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 106/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 107/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 108/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 109/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 110/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 111/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 112/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 113/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 114/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 115/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 116/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 117/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 118/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 119/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 120/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 121/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 122/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 123/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 124/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 125/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 126/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 127/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 128/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 129/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 130/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 131/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 132/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 133/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 134/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 135/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 136/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 137/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 138/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 139/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 140/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 141/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 142/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 143/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 144/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 145/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 146/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 147/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 148/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 149/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 150/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 151/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 152/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 153/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 154/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 155/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 156/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 157/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 158/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 159/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 160/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 161/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 162/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 163/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 164/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 165/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 166/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 167/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 168/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 169/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 170/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 171/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 172/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 173/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 174/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 175/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 176/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 177/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 178/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 179/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 180/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 181/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 182/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 183/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 184/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 185/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 186/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 187/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 188/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 189/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 190/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 191/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 192/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 193/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 194/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 195/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 196/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 197/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 198/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 199/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 200/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 201/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 202/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 203/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 204/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 205/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 206/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 207/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 208/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 209/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 210/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 211/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 212/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 213/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 214/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 215/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 216/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 217/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 218/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 219/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 220/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 221/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 222/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 223/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 224/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 225/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 226/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 227/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 228/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 229/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 230/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 231/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 232/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 233/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 234/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 235/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 236/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 237/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 238/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 239/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 240/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 241/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 242/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 243/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 244/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 245/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 246/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 247/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 248/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 249/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 250/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 251/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 252/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 253/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 254/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 255/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 256/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 257/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 258/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 259/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 260/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 261/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 262/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 263/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 264/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 265/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 266/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 267/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 268/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 269/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 270/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 271/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 272/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 273/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 274/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 275/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 276/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 277/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 278/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 279/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 280/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 281/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 282/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 283/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 284/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 285/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 286/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 287/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 288/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 289/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 290/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 291/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 292/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 293/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 294/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 295/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 296/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 297/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 298/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 299/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 300/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 301/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 302/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 303/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 304/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 305/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 306/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 307/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 308/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 309/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 310/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 311/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 312/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 313/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 314/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 315/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 316/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 317/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 318/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 319/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 320/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 321/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 322/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 323/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 324/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 325/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 326/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 327/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 328/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 329/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 330/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 331/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 332/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 333/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 334/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 335/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 336/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 337/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 338/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 339/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 340/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 341/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 342/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 343/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 344/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 345/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 346/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 347/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 348/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 349/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 350/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 351/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 352/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 353/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 354/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 355/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 356/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 357/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 358/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 359/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 360/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 361/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 362/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 363/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 364/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 365/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 366/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 367/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 368/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 369/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 370/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 371/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 372/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 373/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 374/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 375/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 376/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 377/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 378/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 379/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 380/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 381/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 382/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 383/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 384/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 385/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 386/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 387/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 388/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 389/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 390/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 391/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 392/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 393/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 394/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 395/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 396/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 397/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 398/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 399/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 400/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 401/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 402/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 403/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 404/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 405/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 406/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 407/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 408/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 409/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 410/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 411/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 412/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 413/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 414/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 415/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 416/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 417/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 418/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 419/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 420/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 421/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 422/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 423/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 424/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 425/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 426/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 427/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 428/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 429/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 430/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 431/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 432/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 433/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 434/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 435/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 436/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 437/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 438/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 439/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 440/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 441/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 442/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 443/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 444/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 445/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 446/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 447/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 448/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 449/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 450/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 451/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 452/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 453/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 454/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 455/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 456/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 457/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 458/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 459/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 460/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 461/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 462/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 463/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 464/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 465/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 466/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 467/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 468/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 469/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 470/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 471/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 472/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 473/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 474/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 475/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 476/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 477/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 478/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 479/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 480/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 481/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 482/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 483/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 484/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 485/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 486/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 487/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 488/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 489/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 490/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 491/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 492/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 493/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 494/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 495/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 496/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 497/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 498/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 499/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 500/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 501/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 502/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 503/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 504/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 505/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 506/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 507/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 508/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 509/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 510/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 511/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 512/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 513/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 514/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 515/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 516/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 517/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 518/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 519/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 520/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 521/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 522/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 523/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 524/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 525/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 526/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 527/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 528/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 529/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 530/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 531/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 532/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 533/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 534/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 535/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 536/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 537/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 538/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 539/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 540/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 541/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 542/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 543/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 544/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 545/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 546/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 547/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 548/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 549/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 550/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 551/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 552/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 553/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 554/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 555/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 556/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 557/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 558/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 559/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 560/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 561/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 562/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 563/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 564/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 565/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 566/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 567/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 568/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 569/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 570/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 571/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 572/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 573/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 574/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 575/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 576/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 577/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 578/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 579/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 580/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 581/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 582/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 583/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 584/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 585/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 586/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 587/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 588/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 589/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 590/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 591/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 592/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 593/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 594/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 595/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 596/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 597/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 598/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 599/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 600/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 601/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 602/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 603/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 604/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 605/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 606/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 607/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 608/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 609/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 610/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 611/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 612/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 613/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 614/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 615/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 616/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 617/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 618/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 619/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 620/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 621/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 622/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 623/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 624/626\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 625/626\n",
      "Loaded 8 summaries from cache\n",
      "Adding documents to vectorstore...\n",
      "\n",
      "Processing text batch 2/2\n",
      "Generating summaries for 689 texts...\n",
      "Processing summary batch 1/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 2/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 3/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 4/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 5/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 6/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 7/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 8/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 9/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 10/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 11/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 12/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 13/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 14/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 15/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 16/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 17/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 18/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 19/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 20/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 21/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 22/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 23/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 24/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 25/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 26/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 27/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 28/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 29/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 30/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 31/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 32/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 33/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 34/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 35/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 36/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 37/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 38/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 39/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 40/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 41/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 42/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 43/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 44/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 45/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 46/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 47/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 48/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 49/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 50/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 51/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 52/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 53/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 54/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 55/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 56/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 57/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 58/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 59/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 60/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 61/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 62/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 63/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 64/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 65/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 66/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 67/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 68/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 69/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 70/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 71/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 72/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 73/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 74/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 75/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 76/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 77/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 78/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 79/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 80/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 81/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 82/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 83/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 84/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 85/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 86/87\n",
      "Loaded 8 summaries from cache\n",
      "Processing summary batch 87/87\n",
      "Loaded 8 summaries from cache\n",
      "Adding documents to vectorstore...\n",
      "\n",
      "Persisting vectorstore...\n",
      "\n",
      "Multi-vector retrieval system setup complete!\n",
      "\n",
      "Initializing Groq handler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\896038\\AppData\\Local\\Temp\\ipykernel_23612\\592434953.py:340: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  self.vectorstore.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System ready for queries!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  What is the minimum ventilation requirement for suspended concrete ground floors?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: 4.19 A suspended concrete floor will meet the requirements if it incorporates:\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the context, the minimum ventilation requirement for suspended concrete ground floors is not explicitly stated, but rather it mentions that the floor will meet the requirements if it incorporates certain elements (though the elements are not specified in the given context)."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  What is the minimum ventilation requirement for suspended concrete ground floors?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: 4.19 A suspended concrete floor will meet the requirements if it incorporates:\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the given context, the minimum ventilation requirement for suspended concrete ground floors is not explicitly stated. The context only mentions that a suspended concrete floor will meet the requirements if it incorporates certain features, but it does not specify what those requirements are. Therefore, the minimum ventilation requirement cannot be determined from the provided context."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  Give me the table of Clay type and Volume change potential for site preparation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: Table 1 Volume change potential for some common clays\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, here is the table of Clay type and Volume change potential for site preparation:\n",
      "\n",
      "Unfortunately, the actual table data is not provided in the given context. However, I can suggest the general format of the table based on the description:\n",
      "\n",
      "| Clay Type | Volume Change Potential |\n",
      "| --- | --- |\n",
      "|  |  |\n",
      "\n",
      "Please note that the actual data is missing, and I'm only providing a placeholder table. If you provide the actual table data, I'll be happy to assist you further."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  What are the minimum thickness requirements for solid external walls in traditional construction ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: The walls should have a minimum thickness of 90mm.\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum thickness requirement for solid external walls is 90mm."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  What factors determine the minimum width of strip foundations in different ground conditions?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: Minimum width of strip foundations\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum width of strip foundations is determined by several factors, which vary depending on the ground conditions. These factors include:\n",
      "\n",
      "1. Bearing capacity of the soil: The width of the foundation needs to be sufficient to distribute the load of the structure evenly across the soil, without exceeding the soil's bearing capacity.\n",
      "2. Settlement characteristics: The foundation width should be designed to minimize settlement and ensure that it is uniform across the foundation.\n",
      "3. Soil type and properties: Different soils have varying strengths and settlement characteristics, which affect the required foundation width.\n",
      "4. Load-bearing capacity: The foundation width needs to be sufficient to support the weight of the structure and any external loads.\n",
      "5. Depth of foundation: The depth of the foundation also plays a role in determining the minimum width, as deeper foundations can be narrower due to the increased bearing capacity of the soil at greater depths.\n",
      "\n",
      "In general, the minimum width of strip foundations will vary depending on the specific ground conditions and the design requirements of the structure."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  What design loading must 'key elements' withstand under disproportionate collapse requirements ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: A ‘key element’, as referred to in paragraph 5.1d, should be capable of sustaining an accidental design loading of 34kN/m2 applied in the horizontal and vertical directions (in one direction at a time) to the member and any attached components (e.g. cladding etc.) having regard to the ultimate strength of such components and their connections. Such accidental design loading should be assumed to act simultaneously with all other design loadings (i.e. wind and imposed loading) in accidental actions loading combination.\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the context, 'key elements' must withstand an accidental design loading of 34kN/m2, applied in the horizontal and vertical directions (one direction at a time), in addition to all other design loadings (such as wind and imposed loading)."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  Which geographical areas require special timber treatment against house longhorn ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: 2B2 In the geographical areas specified in Table 1, softwood timber for roof construction or fixed in the roof space, including ceiling joists within the void spaces of the roof, should be adequately treated to prevent infestation by the house longhorn beetle (Hylotrupes bajulus L.).\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The geographical areas that require special timber treatment against house longhorn beetle are specified in Table 1."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  What are the fixing requirements for wall cladding to ensure structural safety ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: 3.1 Wall cladding presents a hazard if it becomes detached from the building. This section provides guidance on the support and fixing of wall cladding. An acceptable level of safety can be achieved by different means depending on the type and location of the cladding. The guidance given relates to all forms of cladding, including curtain walling and glass facades. It is not intended to provide guidance concerning the weather resistance of wall cladding which is included in Approved Document C, Site preparation and resistance to contaminants and moisture, or guidance on resistance to spread of fire which is included in Approved Document B, Fire safety, or guidance in relation to sound insulation, which is included in Approved Document E, Resistance to the passage of sound.\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not explicitly state the specific fixing requirements for wall cladding to ensure structural safety. It mentions that an acceptable level of safety can be achieved by different means depending on the type and location of the cladding, but it does not provide detailed information on the fixing requirements. It also refers to other Approved Documents (C, B, and E) for guidance on weather resistance, fire safety, and sound insulation, but not for structural safety. Therefore, the fixing requirements for wall cladding to ensure structural safety are not specified in the given context."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  What is the minimum subsoil drainage requirement below ground level?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: Section 3: Subsoil drainage\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum subsoil drainage requirement below ground level is not specified in the provided context. The context only mentions \"Section 3: Subsoil drainage\" and a question about the minimum requirement, but it does not provide the actual requirement."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  What are the radon protection requirements in areas with high radon levels?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: • Guidance on radon protective measures.\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempt 1 failed, retrying in 1 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating response (streaming)...\n",
      "\n",
      "Attempt 2 failed, retrying in 2 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating response (streaming)...\n",
      "\n",
      "Error: Failed to generate answer after 3 attempts: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jj0yv8a6fbjsjzm9xvry5zxn` service tier `on_demand` on : Limit 100000, Used 100828, Requested 66. Please try again in 12m52.743999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "Falling back to simple context retrieval. Please rephrase your question.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  What are the radon protection requirements in areas with high radon levels?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: • Guidance on radon protective measures.\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempt 1 failed, retrying in 1 seconds...\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempt 2 failed, retrying in 2 seconds...\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error: Failed to generate answer after 3 attempts: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jj0yv8a6fbjsjzm9xvry5zxn` service tier `on_demand` on : Limit 100000, Used 101258, Requested 66. Please try again in 19m4.579s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "Falling back to simple context retrieval. Please rephrase your question.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  What are the radon protection requirements in areas with high radon levels?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: • Guidance on radon protective measures.\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In areas with high radon levels, the following radon protection requirements are recommended:\n",
      "\n",
      "1. **Sealing entry points**: Seal all entry points where radon can enter the building, such as cracks in floors and walls, and around pipes and electrical outlets.\n",
      "2. **Installing a radon barrier**: Install a radon barrier, such as a plastic sheet, in crawl spaces and under floors to prevent radon from entering the building.\n",
      "3. **Improving ventilation**: Improve ventilation in the building by installing a heat recovery ventilation system or a positive input ventilation system to reduce radon levels.\n",
      "4. **Using radon-resistant materials**: Use radon-resistant materials, such as concrete with a low permeability, for building foundations and floors.\n",
      "5. **Regular testing**: Regularly test for radon levels in the building to ensure that the protection measures are effective.\n",
      "\n",
      "Note: The specific requirements may vary depending on the local regulations and guidelines. It is recommended to consult with a radon expert or a local authority for more detailed guidance."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  What is the minimum ventilation requirement for suspended concrete ground floors?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved content: 4.19 A suspended concrete floor will meet the requirements if it incorporates:\n",
      "\n",
      "Generating response (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the given context, the minimum ventilation requirement for suspended concrete ground floors is not explicitly stated. The context only mentions that a suspended concrete floor will meet the requirements if it incorporates certain features, but it does not specify what those requirements are. Therefore, the minimum ventilation requirement cannot be determined from the provided context."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or 'quit' to exit):  QUIT\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main interactive CLI: lets user choose data source and ask questions\"\"\"\"\n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "    \n",
    "    processor = DataProcessor()\n",
    "    \n",
    "    print(\"\\nSelect data source:\")\n",
    "    print(\"1. YouTube Transcripts\")\n",
    "    print(\"2. PDF Documents\")\n",
    "    print(\"3. Combined Data\")\n",
    "    \n",
    "    choice = input(\"Enter your choice (1-3): \")\n",
    "    \n",
    "    elements = []\n",
    "    if choice == \"1\":\n",
    "        youtube_cache = \"processed_cache/youtube_data.json\"\n",
    "        if os.path.exists(youtube_cache):\n",
    "            elements = processor.load_processed_elements(youtube_cache)\n",
    "        else:\n",
    "            elements = processor.process_youtube_data(\"uk_construction_bot/data/processed/youtube_data.csv\")\n",
    "            processor.save_processed_elements(elements, youtube_cache)\n",
    "    elif choice == \"2\":\n",
    "        pdf_dir = Path(\"uk_construction_bot/data/raw/documents\")\n",
    "        for pdf_file in pdf_dir.glob(\"*.pdf\"):\n",
    "            elements.extend(processor.process_pdf_with_cache(str(pdf_file)))\n",
    "    elif choice == \"3\":\n",
    "        # Load YouTube data\n",
    "        youtube_cache = \"processed_cache/youtube_data.json\"\n",
    "        if os.path.exists(youtube_cache):\n",
    "            youtube_data = processor.load_processed_elements(youtube_cache)\n",
    "        else:\n",
    "            youtube_data = processor.process_youtube_data(\"uk_construction_bot/data/processed/youtube_data.csv\")\n",
    "            processor.save_processed_elements(youtube_data, youtube_cache)\n",
    "        \n",
    "        #Loading PDF data\n",
    "        pdf_elements = []\n",
    "        pdf_dir = Path(\"uk_construction_bot/data/raw/documents\")\n",
    "        for pdf_file in pdf_dir.glob(\"*.pdf\"):\n",
    "            pdf_elements.extend(processor.process_pdf_with_cache(str(pdf_file)))\n",
    "        \n",
    "        elements = youtube_data + pdf_elements\n",
    "    else:\n",
    "        print(\"Invalid choice\")\n",
    "        return\n",
    "    \n",
    "    if not elements:\n",
    "        print(\"No elements to process\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        print(\"\\nSetting up retrieval system...\")\n",
    "        processor.setup_retrieval_system(elements)\n",
    "        \n",
    "        print(\"\\nInitializing Groq handler...\")\n",
    "        groq_handler = GroqHandler(\n",
    "            api_key=\"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\" ##this api key has been disabled, its not good to expose keys but for testing anf detection I exposed and disabled it afterwards, this applies to any other key seen within the 3 notebooks I used for thsi development.\n",
    "        )\n",
    "        \n",
    "        print(\"\\nSystem ready for queries!\")\n",
    "        \n",
    "        # Interactive QA\n",
    "        while True:\n",
    "            try:\n",
    "                question = input(\"\\nEnter your question (or 'quit' to exit): \")\n",
    "                if question.lower() == 'quit':\n",
    "                    break\n",
    "                    \n",
    "                retrieved = processor.retriever.invoke(question)\n",
    "                if not retrieved:\n",
    "                    print(\"\\nNo relevant information found in the documents.\")\n",
    "                    continue\n",
    "                    \n",
    "                context = retrieved[0].page_content\n",
    "                print(\"\\nRetrieved content:\", context)\n",
    "                \n",
    "                response = groq_handler.generate_answer(context, question)\n",
    "                if not response:\n",
    "                    print(\"\\nFalling back to simple context retrieval. Please rephrase your question.\")\n",
    "                    \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nExiting QA session...\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"\\nUnexpected error in QA: {str(e)}\")\n",
    "                print(\"Please try again with a different question.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in setup: {str(e)}\")\n",
    "        print(\"Processed elements have been cached and can be reused on next run.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033fc361-5e60-4cbb-b595-68bb96b00743",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The end of the code execution output above has an interactive Rag System which I used to test out here before taking to build a proper user interface \n",
    "## via streamlit and deploying that interface on HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e46eff8-c44f-4313-b657-78468d61fb2d",
   "metadata": {},
   "source": [
    "### Groq's Llama-3.3-70b model through their API HuggingFace embeddings (sentence-transformers/all-mpnet-base-v2)\n",
    "Currently, the code uses DistilBART for summarization, specifically the \"sshleifer/distilbart-cnn-12-6\" model. This can be seen in the generate_summaries_batch function within the setup_retrieval_system method:\n",
    "This summarization is used as part of the multi-vector retrieval system, where both full documents and their summaries are stored for improved retrieval performance.\n",
    "\n",
    "This code is a RAG (Retrieval Augmented Generation) system that processes documents and answers questions about them. Here's the key functionality:\n",
    "\n",
    "Document Processing: Processes both PDF documents and YouTube transcripts\n",
    "Uses Unstructured API to extract text and tables from PDFs\n",
    "Caches processed documents to avoid reprocessing\n",
    "\n",
    "\n",
    "Embedding and Storage:Currently uses HuggingFace embeddings (sentence-transformers/all-mpnet-base-v2)\n",
    "Stores embeddings in a Chroma vector database\n",
    "Uses a multi-vector retrieval system that stores both full content and summaries\n",
    "\n",
    "\n",
    "Text Generation:Currently uses Groq's Llama-3.3-70b model through their API\n",
    "Includes retry logic and error handling\n",
    "Uses a streaming response system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724ad43a-4470-4805-b9bd-537bbb31ce4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
